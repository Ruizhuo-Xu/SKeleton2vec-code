train_dataset:
  dataset:
    name: PoseDataset
    args:
      anno_file: data/pku/pkuv1_3danno.pkl
      pipelines: [
        {name: PreNormalize3D, args: {align_spine: false}},
        {name: RandomRot, args: {theta: 0.3}},
        {name: GenSkeFeat, args: {dataset: 'nturgb+d', feats:['j']}},
        {name: UniformSampleDecode, args: {clip_len: 90}},
        # {name: RandomResizedCrop, args: {p_interval: [0.5, 1.0], clip_len: 120}},
        {name: FormatGCNInput, args: {}},
        {name: Collect, args: {keys: [keypoint, label], meta_keys: []}},
        {name: ToTensor, args: {keys: [keypoint, label]}},
      ]
      split: xsub_train
      # first_k: 100
  batch_size: 64
  num_workers: 4

val_dataset:
  dataset:
    name: PoseDataset
    args:
      anno_file: data/pku/pkuv1_3danno.pkl
      pipelines: [
        {name: PreNormalize3D, args: {align_spine: false}},
        {name: GenSkeFeat, args: {dataset: 'nturgb+d', feats:['j']}},
        {name: UniformSampleDecode, args: {clip_len: 90}},
        # {name: RandomResizedCrop, args: {p_interval: [0.95, 0.95], clip_len: 120}},
        {name: FormatGCNInput, args: {}},
        {name: Collect, args: {keys: [keypoint, label], meta_keys: []}},
        {name: ToTensor, args: {keys: [keypoint, label]}},
      ]
      split: xsub_val
  batch_size: 128
  num_workers: 4

model:
  name: SkTForClassification
  args:
    encoder_spec:
      name: SkT
      args:
        in_channels: 3
        temporal_segment_size: 3
        spatio_size: 25
        temporal_size: 90
        emb_size: 256
        depth: 8
        num_heads: 8
        att_drop_p: 0.
        forward_drop_p: 0.
        drop_path_p: 0.
    cls_head_spec:
      name: ClassificationHeadLight
      args:
        n_classes: 60
        num_persons: 2
        drop_p: 0.
    # encoder_pretrain_weight: save/pkuv1_xsub_pretrain_skt2vec2_64BSZ_3D_1e-3baseLR_1e-5minLR_tube5_tau0.2_ema999_800EP/epoch-800.pth
    encoder_pretrain_weight: save/pkuv1_xsub_pretrain_skt2vec2_64BSZ_3D_1e-3baseLR_1e-5minLR_tube5_tau0.2_ema9999_800EP_/epoch-800.pth
    
    encoder_freeze: true
    drop_path_p: 0.
  
# resume: save/nturgbd60_pretrain_test_bz64-lr3e-4-mask0.8-wd1e-2-L2/epoch-last.pth

optimizer:
  name: sgd
  args:
    lr: 0.1
    momentum: 0.9
    weight_decay: 0.
epoch_max: 100

lr_scheduler:
  name: CosineDecayWithWarmup
  args:
    warmup_epochs: 0
    max_epochs: 100
    base_lr: 0.01
    min_lr: 0.
    mode: step
# lr_scheduler:
#   name: MultiStepLr
#   args:
#     milestones: [10, 30, 50]
#     gamma: 0.1
    

label_smoothing: 0.
epoch_val: 1
epoch_save: 200
mode: linear_probe
